<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>集成学习-bagging</title>
      <link href="2021/04/16/bagging/"/>
      <url>2021/04/16/bagging/</url>
      
        <content type="html"><![CDATA[<p>与投票法不同，Bagging不仅仅集成模型最后的预测结果，同时采用一定策略来影响基模型训练，保证基模型可以服从一定的假设。集成学习我们希望各个模型之间具有较大的差异性，而在实际操作中的模型往往是同质的，因此一个简单的思路是通过不同的采样增加模型的差异性。</p><h2 id="bagging的原理分析"><a href="#bagging的原理分析" class="headerlink" title="bagging的原理分析"></a>bagging的原理分析</h2><p>bagging的核心在于<font color="red">自主采样（bootstrap）</font>，即有放回的从数据集中进行采样，也就是说，同样一个样本可能被多次进行采样。一个自主采样的例子是希望估计全国所有人口年龄的平均值，那么我们在全国所有人口中随机抽取不同的集合（这些集合可能存在交集），计算每个集合的平均值，然后将所有平均值的均值作为估计值。</p><h3 id="bagging的基本流程"><a href="#bagging的基本流程" class="headerlink" title="bagging的基本流程"></a>bagging的基本流程</h3><ul><li>随机取出一个样本放入采样集合中，再把这个样本放回初始数据集，重复K次采样。最终获得一个大小为K的样本集合。</li><li>同样的方法，可以采样出T个含K个样本的采样集合，然后基于每个采样集合训练出一个基学习器，再将这些基学习器进行结合，就是Bagging的基本流程。</li></ul><p>对于回归问题的预测是通过预测取平均值来进行的，对于分类问题的预测是通过预测取多数票预测来进行的。 Bagging方法之所以有效，是因为每个模型都是再略微不同的训练数据集上拟合完成的，这又使得每个基模型之间存在略微的差异，使每个基模型拥有略微不同的训练能力。<br>bagging同样是一种降低方差的技术，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效果更将明显，在实际的使用中，加入列采样的Bagging技术对高维小样本往往有神奇的效果。</p><p>行采样，列采样是随机森林、XGBoost等集成模型中常用的trick。主要作用是加快训练速度和防止过拟合。<br>随机森林：1）建树前对样本随机抽样（行采样）2）每个特征分裂随机采样生成特征候选集（列采样）3）根据增益公式选取最优分裂特征和对应特征分裂建树。建树过程完全独立。能够完全并行化。</p><h2 id="bagging的案例分析"><a href="#bagging的案例分析" class="headerlink" title="bagging的案例分析"></a>bagging的案例分析</h2><p>Sklearn 提供了BaggingRegressor和BaggingClassifier两种Bagging方法的API，这两种方法的默认基模型是树模型。树一般指的是决策树，是一种树形结构，树的每个非叶子节点表示对样本在一个特征上的判断，节点下方的分支代表对样本的划分。决策树的建立过程是对一个数据不断划分的过程，每次划分中，首先要选择用于划分的特征，之后要确定划分的方案（类别/阈值）。我们希望通过划分，决策树的分支节点所包含的样本“纯度”尽可能高，节点划分过程中所用的指标主要是<font color="red">信息增益</font>和<font color="red">GINI系数</font>  </p><h3 id="决策树分裂"><a href="#决策树分裂" class="headerlink" title="决策树分裂"></a>决策树分裂</h3><p>信息增益： 衡量的是划分前后不确定性程度的减小，信息不确定程度一般使用信息熵来度量，计算方式是：<br>$H(Y) = -\sum{p_{i}logp_{i}}$<br>i表示样本的标签，p表示该样本出现的概率，当我们对样本进行划分之后，计算样本的条件熵：<br>$H(Y|X) = -\sum_{x \in X}{p(X = x)H(Y|X = x)}$<br>其中X表示用于划分特征的取值。信息增益定义为信息熵与条件熵的差值：<br>$IG = H(Y) - H(Y|X)$<br>信息增益IG越大，说明使用该特征划分数据所获得的信息量变化越大，子节点的样本”纯度“越高。<br>同样，也可以利用Gini指数来衡量数据的不纯度，计算方法 $Gini = 1 - \sum p_{i}^{2}$<br>对样本做出划分后，计算划分后的Gini指数 $Gini_{x} = \sum_{x \in X}p(X = x)[1 - \sum p_{i}^2]$<br>选择使得划分后Gini指数最小的特征。</p><h4 id="分裂举例"><a href="#分裂举例" class="headerlink" title="分裂举例"></a>分裂举例</h4><p><img src="/2021/04/16/bagging/%E5%86%B3%E7%AD%96%E6%A0%91.jpg" alt="决策树"></p><p>根据天气、温度和风力等级判断是否打网球：首先通过计算信息增益 or Gini指数确定首先根据天气情况对样本进行划分，之后对于每个分支，继续考虑除天气之外的其他特征，直到样本的类型被完全分开，所有特征都已使用，或达到树的最大深度为止。<br>Bagging的一个典型应用是随机森林，”森林“是许多树bagging组成，具体实现上，用于每个决策树训练的样本和构建决策树的特征都是通过随机采样得到的，RF的预测结果是多个决策树输出的组合（投票）</p><p><img src="/2021/04/16/bagging/%E5%86%B3%E7%AD%96%E6%A0%91%E8%BF%87%E7%A8%8B.jpg" alt="决策树"></p><h3 id="sklearn-bagging-代码"><a href="#sklearn-bagging-代码" class="headerlink" title="sklearn bagging 代码"></a>sklearn bagging 代码</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_classificationX<span class="token punctuation">,</span>y <span class="token operator">=</span> make_classification<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> n_informative<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span>n_redundant<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> RepeatedStratifiedKFold<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> BaggingClassifier<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># define the model</span>model <span class="token operator">=</span> BaggingClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># evaluate the model</span><span class="token comment"># 使用重复的分层k-fold交叉验证来评估模型，一共重复3次，每次有10个fold，</span>cv <span class="token operator">=</span> RepeatedStratifiedKFold<span class="token punctuation">(</span>n_splits <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>n_repeats <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>n_scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> scoring <span class="token operator">=</span> <span class="token string">"accuracy"</span><span class="token punctuation">,</span> cv <span class="token operator">=</span> cv<span class="token punctuation">,</span> n_jobs <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> error_score <span class="token operator">=</span> <span class="token string">"raise"</span><span class="token punctuation">)</span><span class="token comment"># report performance</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy : %.3f(%.3f)"</span><span class="token operator">%</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>n_scores<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>n_scores<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(1000, 20) (1000,)<br>Accuracy : 0.858(0.034)</p><h3 id="sklearn-ensemble-BaggingClassifier"><a href="#sklearn-ensemble-BaggingClassifier" class="headerlink" title=" sklearn.ensemble.BaggingClassifier "></a><strong><font face="微软雅黑" size="3" color="#BA55D3"> sklearn.ensemble.BaggingClassifier </font></strong></h3><h4 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h4><ul><li>base_estimator : object, default=None<br>The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a DecisionTreeClassifier.</li><li>n_estimators : int, default=10<br>The number of base estimators in the ensemble.</li><li>max_samples : int or float, default=1.0<br>The number of samples to draw from X to train each base estimator (with replacement by default, see bootstrap for more details).</li><li>max_features : int or float, default=1.0<br>The number of features to draw from X to train each base estimator ( without replacement by default, see bootstrap_features for more details).<ul><li>If int, then draw max_features features.</li><li>If float, then draw max_features * X.shape[1] features.</li></ul></li><li>bootstrap : bool, default=True<br>Whether samples are drawn with replacement. If False, sampling without replacement is performed.  </li></ul><h3 id="sklearn-datasets-make-classifsication"><a href="#sklearn-datasets-make-classifsication" class="headerlink" title=" sklearn.datasets.make_classifsication "></a><strong><font face="微软雅黑" size="3" color="#BA55D3"> sklearn.datasets.make_classifsication </font></strong></h3><p>Generate a random n-class classification problem.<br>创建一个长度为2*class_sep 且边长为 2 * class_sep 的正态分布于n_informative-维超立方体的顶点的点簇（std =1），并为每个类分配相等数量的簇。<br>n_informative 特征， n_redundant 线性的信息特征组合，n_repeated 重复，从信息和冗余特征中随机替换。</p><h4 id="Parameters-1"><a href="#Parameters-1" class="headerlink" title="Parameters"></a>Parameters</h4><ul><li>n_samples: int, default = 100, the number of samples.</li><li>n_features: int, default = 20, The total number of features. </li><li>n_informative:int， default = 2</li><li>n_redundant:int， default = 2</li><li>n_repeated:int， default = 0</li><li>n_classes: int, default = 2</li><li>n_cluster_per_class, int, default = 2</li><li>weights: array-like of shape(n_classes, ) or (n_classes-1, ), default = None</li><li>flip_y: float, default = 0.01</li><li>class_sep：float, default = 1.0</li><li>hypercube: bool, default = True</li><li>shift:float, ndarray of shape (n_features,) or None, default=0.0</li><li>scale: float, ndarray of shape (n_features,) or None, default=1.0</li><li>shuffle: bool, default=True</li><li>random_state: int, RandomState instance or None, default=None</li></ul><h4 id="Returns"><a href="#Returns" class="headerlink" title="Returns"></a>Returns</h4><ul><li>X : ndarray of shape (n_samples, n_features)<br>  The generated samples</li><li>y : ndarray of shape (n_samples)<br>  The integer labels for class membership of each sample.</li></ul><h3 id="sklearn-model-selection-RepeatedStratifiedKFold"><a href="#sklearn-model-selection-RepeatedStratifiedKFold" class="headerlink" title=" sklearn.model_selection.RepeatedStratifiedKFold "></a><strong><font face="微软雅黑" size="3" color="#BA55D3"> sklearn.model_selection.RepeatedStratifiedKFold </font></strong></h3><h4 id="为什么使用交叉验证（监督学习器性能评估方法）"><a href="#为什么使用交叉验证（监督学习器性能评估方法）" class="headerlink" title="为什么使用交叉验证（监督学习器性能评估方法）"></a>为什么使用交叉验证（监督学习器性能评估方法）</h4><p>一般情况下，我们将原始数据集分为训练数据集和验证数据集。防止训练过程中数据泄露，从训练数据集中划分出一部分数据，validation set（验证数据集），用来评估模型。最后再用测试集检验模型的泛化能力。<br>但是把原始数据集分割之后，用来训练模型的数据集大大减小，同时训练结果也更大的依赖于训练数据集和测试数据集占原始数据集的比重。 解决方法即 cross-validation 交叉检验，缩写cv。<br>k-fold cv的基本方法中，训练集被划分为k个较小的集合k-folds. 分别让一个fold作为测试集，余下部分作为训练集，进行k次训练，共计得到k个参数。最终使用均值作为最终的模型参数。  </p><p><img src="/2021/04/16/bagging/cv.jpg" alt="交叉验证"></p><p>缺点：相同大小的数据集，需要进行更多的运算。<br>优点：最大特点是不浪费validation set大小的数据，尤其是在样本集不够大的情况下。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">sklearn</span><span class="token punctuation">.</span>model_selection<span class="token punctuation">.</span>RepeatedStratifiedKFold<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">,</span> n_splits<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> n_repeats<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Parameters-2"><a href="#Parameters-2" class="headerlink" title="Parameters"></a>Parameters</h4><ul><li>n_splits : int, default=5, Number of folds. Must be at least 2.</li><li>n_repeats : int, default=10, Number of times cross-validator needs to be repeated.</li><li>random_state : int, RandomState instance or None, default=None</li></ul><h3 id="sklearn-model-selection-cross-val-score"><a href="#sklearn-model-selection-cross-val-score" class="headerlink" title=" sklearn.model_selection.cross_val_score "></a><strong><font face="微软雅黑" size="3" color="#BA55D3"> sklearn.model_selection.cross_val_score </font></strong></h3><p>Evaluate a score by cross-validation</p><h4 id="Parameters-3"><a href="#Parameters-3" class="headerlink" title="Parameters"></a>Parameters</h4><ul><li>estimator：estimator object implementing ‘fit’.</li><li>X: array-like of shape ( n_samples, n_features).</li><li>y: array-like of shape (n_samples,) or (n_samples, n_outputs), default=None.</li><li>groups: array-like of shape (n_samples,), default=None.</li><li>scoring: str or callable, default=None.</li><li>cv: int, cross-validation generator or an iterable, default=None<ul><li>None, to use the default 5-fold cross validation</li><li>int, to specify the number of folds in a (Stratified)KFold</li><li>CV splitter</li><li>An iterable yielding (train, test) splits as arrays of indices.</li></ul></li></ul><h4 id="Returns-1"><a href="#Returns-1" class="headerlink" title="Returns"></a>Returns</h4><ul><li>scores : ndarray of float of shape=(len(list(cv)),)<ul><li>Array of scores of the estimator for each run of the cross validation.</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> DataWhale </tag>
            
            <tag> ensemble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习-基础</title>
      <link href="2021/04/15/machine-learning/"/>
      <url>2021/04/15/machine-learning/</url>
      
        <content type="html"><![CDATA[<h2 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h2><ul><li>机器学习<ul><li>有监督学习 ：有因变量，有特征向量，预测结果。  <ul><li> 回归：因变量是连续型变量，如：房价、体重等。</li><li> 分类：因变量是离散型变量，如：是否患癌症，西瓜是好瓜 or 坏瓜。</li></ul></li><li>无监督学习 ：无因变量，有特征向量，寻找数据中的结构。</li></ul></li></ul><h2 id="投票法的原理分析"><a href="#投票法的原理分析" class="headerlink" title="投票法的原理分析"></a>投票法的原理分析</h2><p>投票法是一种遵循少数服从多数原则的集成学习模型，通过多个模型的集成降低方差，从而提高模型的鲁棒性。理想情况下，投票法的预测效果优于任何一个基模型的预测效果。<br>投票法在回归模型与分类模型上均可使用：  </p><ul><li>回归投票法：预测结果是所有模型预测结果的平均值。  </li><li>分类投票法：预测结果是所有模型中出现最多的预测结果。</li></ul><p>分类投票法又可以划分为硬投票与软投票：  </p><ul><li>硬投票：预测结果是所有投票结果最多出现的类。</li><li>软投票：预测结果是所有投票结果中出现概率加和最大的类。</li></ul><p>例子：<br> 硬投票：对于某个样本 ，模型1的预测结果是A， 模型2的预测结果是B，模型3的预测结果是B。 硬投票法的预测结果是B。<br> 软投票：model 1 类型A的概率是99%，model 2 类型A的概率是49%，model 3类型A的概率是49%。 A的预测概率的平均是（99+49+49）/3 = 65.67%。<br> 软投票考虑到预测概率这一额外信息，因此比硬投票法更加准确的预测结果。  </p><p>在投票法中，需要考虑到不同的基模型可能产生的影响。理论上，基模型可以是任何已被训练好的模型，在实际应用上，想要投票法产生较好的结果，需要满足两个条件：  </p><ul><li>基模型之间的效果不能差别过大，当某个及模型相对于其他基模型效果过差时，该模型很可能成为噪声。</li><li>基模型之间应该有较小的同质性， 例如在基模型预测效果近似的情况下，基于树模型与线性模型的投票，往往优于两个树模型或两个线性模型。</li></ul><p>当投票集合中使用的模型能预测出清晰的类别标签时，适合使用硬投票。<br>当投票集合使用的模型能预测类别的概率时，适合使用软投票。软投票同样可以用于那些本身并不预测类成员概率的模型，只要他们可以输出类似于概率的预测分数值（SVM，k-最近邻和决策树）</p><h2 id="投票法案例"><a href="#投票法案例" class="headerlink" title="投票法案例"></a>投票法案例</h2><p>sklearn中两种投票方法 VotingRegressor和VotingClassifier两个投票方法。这两种模型的操作方式相同，并采用相同的参数，使用模型需要提供一个模型列表，列表中每个模型采用Tuple的结构表示，第一个元素代表名称，第二个元素代表模型，需要保证每个模型必须拥有唯一的名称。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> VotingClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token comment"># 创建1000个样本，20个特征的随机数据集</span><span class="token comment"># test classification dataset</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_classification<span class="token comment"># define dataset</span><span class="token keyword">def</span> <span class="token function">get_dataset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_classification<span class="token punctuation">(</span>n_samples <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> n_features <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span> n_informative <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">,</span> n_redundant<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment"># summarize the dataset</span>    <span class="token keyword">return</span> X<span class="token punctuation">,</span>yX<span class="token punctuation">,</span>y <span class="token operator">=</span> get_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 使用多个KNN模型作为基模型演示投票法，其中每个模型采用不同邻居值K参数：</span><span class="token comment"># get a voting ensemble of models</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier<span class="token keyword">def</span> <span class="token function">get_voting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># define the base models</span>    models <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn1'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn3'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn5'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn7'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn9'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># define the voting ensemble</span>    ensemble <span class="token operator">=</span> VotingClassifier<span class="token punctuation">(</span>estimators <span class="token operator">=</span> models<span class="token punctuation">,</span> voting <span class="token operator">=</span> <span class="token string">"hard"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> ensemble<span class="token comment"># 创建模型列表，包括每个基模型和硬投票模型</span><span class="token comment"># get a list of models to evaluate</span><span class="token keyword">def</span> <span class="token function">get_models</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    models <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn5'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn7'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">7</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn9'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">9</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'hard_voting'</span><span class="token punctuation">]</span> <span class="token operator">=</span> get_voting<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> models<span class="token comment"># evaluate a give model using cross_valiation</span><span class="token comment"># 分层10倍交叉验证三次重复的分数列表的形式返回</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span>  RepeatedStratifiedKFold<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    cv <span class="token operator">=</span> RepeatedStratifiedKFold<span class="token punctuation">(</span>n_splits <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> n_repeats <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>    scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y <span class="token punctuation">,</span>scoring <span class="token operator">=</span> <span class="token string">"accuracy"</span><span class="token punctuation">,</span> cv <span class="token operator">=</span> cv<span class="token punctuation">,</span> n_jobs <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> error_score <span class="token operator">=</span> <span class="token string">"raise"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> scores<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npmodels <span class="token operator">=</span> get_models<span class="token punctuation">(</span><span class="token punctuation">)</span>results<span class="token punctuation">,</span> names <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> model <span class="token keyword">in</span> models<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scores <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>    names<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"&gt;%s %.3f (%.3f)"</span><span class="token operator">%</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplotpyplot<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>results<span class="token punctuation">,</span> labels <span class="token operator">=</span> names<span class="token punctuation">,</span> showmeans <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>pyplot<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/04/15/machine-learning/voting_result.jpg" alt="输出结果"></p>]]></content>
      
      
      
        <tags>
            
            <tag> DataWhale </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智慧海洋-基础学习</title>
      <link href="2021/04/15/ais_analysis/"/>
      <url>2021/04/15/ais_analysis/</url>
      
        <content type="html"><![CDATA[<h2 id="常用空间数据计算与分析工具"><a href="#常用空间数据计算与分析工具" class="headerlink" title="常用空间数据计算与分析工具"></a>常用空间数据计算与分析工具</h2><ul><li>shapely<ul><li>空间数据模型</li><li>几何对象的一些功能特性<br>Point，LineStrings，LineRings，Polygon</li><li>几何对象之间的关系</li></ul></li><li>geopandas</li><li>Folium</li><li>Kepler.gl</li><li>GeoHash</li></ul><h3 id="geohash"><a href="#geohash" class="headerlink" title="geohash"></a>geohash</h3><p>geohash基本原理是将地球理解为一个二维平面，将平面递归分解成更小的子块，每个子块在一定经纬度范围内拥有相同的编码。可以满足对小规模数据进行经纬度的检索。<br><img src="/2021/04/15/ais_analysis/earth.jpg" alt="地球">  </p><ul><li>纬线：地球仪上的横线 ， lat， 赤道是最大的纬线，从赤道开始分为北纬和南纬，都是0-90°，纬线是角度数值，不是米。</li><li>经线：地球仪上的竖线，lon，子午线是0°，分为西经和东经，都是0-180°，经线也是角度数值。</li><li>将地球看成一个基于经纬度线的坐标系。纬线就是平行于赤道平面的那些平面的周线，经线就是连接南北两极的大园线的半圆弧。纬度分为北纬（正），南纬（负），赤道所在的纬度值为0，经度以本初子午线界（本初子午线经度为0），分为东经（正），西经（负）。lat范围[-90°，0°)，(0°，90°],纬度范围表示为[-180°，0°），（0°，180°]。  </li></ul><p><img src="/2021/04/15/ais_analysis/%E4%BA%8C%E4%BD%8D%E5%9D%90%E6%A0%87.jpg" alt="二维坐标"> </p><p>GeoHash将二维的经纬度转换成字符串，比如下图展示了北京9个区域的GeoHash字符串，分别是WX4ER，WX4G2、WX4G3等等，每一个字符串代表了某一矩形区域。也就是说，这个矩形区域内所有的点（经纬度坐标）都共享相同的GeoHash字符串，这样既可以保护隐私（只表示大概区域位置而不是具体的点），又比较容易做缓存。</p><ul><li>不同的编码长度，表示不同的范围区间，字符串越长，表示的范围越精确。</li><li>字符串相似的表示距离相近（特殊情况后文阐述），这样可以利用字符串的前缀匹配来查询附近的POI信息。如下两个图所示，一个在城区，一个在郊区，城区的GeoHash字符串之间比较相似，郊区的字符串之间也比较相似，而城区和郊区的GeoHash字符串相似程度要低些。  </li></ul><p>GeoHash就是一种将经纬度转换成字符串的方法，并且使得在大部分情况下，字符串前缀匹配越多的距离越近</p><h2 id="基于kepler-gl可视化不同类型的船舶数据"><a href="#基于kepler-gl可视化不同类型的船舶数据" class="headerlink" title="基于kepler.gl可视化不同类型的船舶数据"></a>基于kepler.gl可视化不同类型的船舶数据</h2><h2 id="douglas-peucker算法识别关键数据点"><a href="#douglas-peucker算法识别关键数据点" class="headerlink" title="douglas-peucker算法识别关键数据点"></a>douglas-peucker算法识别关键数据点</h2>]]></content>
      
      
      
        <tags>
            
            <tag> DataWhale </tag>
            
            <tag> AIS </tag>
            
            <tag> GeoPandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集成学习-投票法</title>
      <link href="2021/04/14/voting/"/>
      <url>2021/04/14/voting/</url>
      
        <content type="html"><![CDATA[<h2 id="投票法的基本思路"><a href="#投票法的基本思路" class="headerlink" title="投票法的基本思路"></a>投票法的基本思路</h2><p>融合多个数据降低误差。  </p><h2 id="投票法的原理分析"><a href="#投票法的原理分析" class="headerlink" title="投票法的原理分析"></a>投票法的原理分析</h2><p>投票法是一种遵循少数服从多数原则的集成学习模型，通过多个模型的集成降低方差，从而提高模型的鲁棒性。理想情况下，投票法的预测效果优于任何一个基模型的预测效果。<br>投票法在回归模型与分类模型上均可使用：  </p><ul><li>回归投票法：预测结果是所有模型预测结果的平均值。  </li><li>分类投票法：预测结果是所有模型中出现最多的预测结果。</li></ul><p>分类投票法又可以划分为硬投票与软投票：  </p><ul><li>硬投票：预测结果是所有投票结果最多出现的类。</li><li>软投票：预测结果是所有投票结果中出现概率加和最大的类。</li></ul><p>例子：<br> 硬投票：对于某个样本 ，模型1的预测结果是A， 模型2的预测结果是B，模型3的预测结果是B。 硬投票法的预测结果是B。<br> 软投票：model 1 类型A的概率是99%，model 2 类型A的概率是49%，model 3类型A的概率是49%。 A的预测概率的平均是（99+49+49）/3 = 65.67%。<br> 软投票考虑到预测概率这一额外信息，因此比硬投票法更加准确的预测结果。  </p><p>在投票法中，需要考虑到不同的基模型可能产生的影响。理论上，基模型可以是任何已被训练好的模型，在实际应用上，想要投票法产生较好的结果，需要满足两个条件：  </p><ul><li>基模型之间的效果不能差别过大，当某个及模型相对于其他基模型效果过差时，该模型很可能成为噪声。</li><li>基模型之间应该有较小的同质性， 例如在基模型预测效果近似的情况下，基于树模型与线性模型的投票，往往优于两个树模型或两个线性模型。</li></ul><p>当投票集合中使用的模型能预测出清晰的类别标签时，适合使用硬投票。<br>当投票集合使用的模型能预测类别的概率时，适合使用软投票。软投票同样可以用于那些本身并不预测类成员概率的模型，只要他们可以输出类似于概率的预测分数值（SVM，k-最近邻和决策树）</p><h2 id="投票法案例"><a href="#投票法案例" class="headerlink" title="投票法案例"></a>投票法案例</h2><p>sklearn中两种投票方法 VotingRegressor和VotingClassifier两个投票方法。这两种模型的操作方式相同，并采用相同的参数，使用模型需要提供一个模型列表，列表中每个模型采用Tuple的结构表示，第一个元素代表名称，第二个元素代表模型，需要保证每个模型必须拥有唯一的名称。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> VotingClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token comment"># 创建1000个样本，20个特征的随机数据集</span><span class="token comment"># test classification dataset</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_classification<span class="token comment"># define dataset</span><span class="token keyword">def</span> <span class="token function">get_dataset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_classification<span class="token punctuation">(</span>n_samples <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> n_features <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span> n_informative <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">,</span> n_redundant<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment"># summarize the dataset</span>    <span class="token keyword">return</span> X<span class="token punctuation">,</span>yX<span class="token punctuation">,</span>y <span class="token operator">=</span> get_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 使用多个KNN模型作为基模型演示投票法，其中每个模型采用不同邻居值K参数：</span><span class="token comment"># get a voting ensemble of models</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier<span class="token keyword">def</span> <span class="token function">get_voting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># define the base models</span>    models <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn1'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn3'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn5'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn7'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    models<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'knn9'</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># define the voting ensemble</span>    ensemble <span class="token operator">=</span> VotingClassifier<span class="token punctuation">(</span>estimators <span class="token operator">=</span> models<span class="token punctuation">,</span> voting <span class="token operator">=</span> <span class="token string">"hard"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> ensemble<span class="token comment"># 创建模型列表，包括每个基模型和硬投票模型</span><span class="token comment"># get a list of models to evaluate</span><span class="token keyword">def</span> <span class="token function">get_models</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    models <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn5'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn7'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">7</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'knn9'</span><span class="token punctuation">]</span> <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">9</span><span class="token punctuation">)</span>    models<span class="token punctuation">[</span><span class="token string">'hard_voting'</span><span class="token punctuation">]</span> <span class="token operator">=</span> get_voting<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> models<span class="token comment"># evaluate a give model using cross_valiation</span><span class="token comment"># 分层10倍交叉验证三次重复的分数列表的形式返回</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span>  RepeatedStratifiedKFold<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    cv <span class="token operator">=</span> RepeatedStratifiedKFold<span class="token punctuation">(</span>n_splits <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> n_repeats <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>    scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y <span class="token punctuation">,</span>scoring <span class="token operator">=</span> <span class="token string">"accuracy"</span><span class="token punctuation">,</span> cv <span class="token operator">=</span> cv<span class="token punctuation">,</span> n_jobs <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> error_score <span class="token operator">=</span> <span class="token string">"raise"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> scores<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npmodels <span class="token operator">=</span> get_models<span class="token punctuation">(</span><span class="token punctuation">)</span>results<span class="token punctuation">,</span> names <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> model <span class="token keyword">in</span> models<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scores <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>    names<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"&gt;%s %.3f (%.3f)"</span><span class="token operator">%</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplotpyplot<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>results<span class="token punctuation">,</span> labels <span class="token operator">=</span> names<span class="token punctuation">,</span> showmeans <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>pyplot<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/04/14/voting/voting_result.jpg" alt="输出结果"></p>]]></content>
      
      
      
        <tags>
            
            <tag> DataWhale </tag>
            
            <tag> ensemble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zhou Jiaqi</title>
      <link href="2021/04/09/hello-world/"/>
      <url>2021/04/09/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to Jiaqi’s World</p><p><strong><font face="微软雅黑" color="#FF9900"> EDUCATION </font></strong>  </p><ul><li>Beijing Institute of Technology (985), Sep.2016-Jun.2019<ul><li>Master in Computer Science and Technology , GPA 3.4/4.0</li><li>2019 Beijing outstanding graduates, </li><li>2016-2018 School-based professional for a scholarship</li></ul></li><li>Beijing Institute of Technology (985), Sep.2012-Jun.2016<ul><li>Bachelor in Computer Science and Technology , GPA 3.4/4.0</li><li>Double degree in economics  </li></ul></li></ul><p><strong><font face="微软雅黑" color="#FF9900"> WORK EXPERIENCE </font></strong>   </p><ul><li>ChinaSatcom (full time)</li><li>Face ++ (internship)</li><li>JD(internship)</li><li>Baidu(intership)</li><li>NCI（intership）</li></ul><p><strong><font face="微软雅黑" color="#FF9900"> PROJECT EXPERIENCE </font></strong>  </p><ul><li>user behavior prediction in news recommendation scenarios</li><li>text recommendation</li><li>Chinese Pre-training Model generalization ability challenge</li></ul><p><strong><font face="微软雅黑" color="#FF9900"> SKILLS </font></strong>  </p><ul><li>Programming language ： familiar with Python、C++、Shell、SQL</li><li>Professional framework ： familiar with tensorflow、sklearn、pandas、numpy，matplotlib，etc.</li><li>Algorithm   <ul><li>machine learning algorithms: familiar with LR、bayes、K-means、GBDT，etc.</li><li>deep learning algorithms: CNN、RNN、LSTM etc.</li><li>text processing: familiar with TF-IDF, word2vec, bert.</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> JIAQI ZHOU </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
